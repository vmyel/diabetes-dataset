{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9046616",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOADING DATASETS\n",
      "==================================================\n",
      "1. Anthropometric data: (444400, 18)\n",
      "2. Clinical data: (351701, 29)\n",
      "3. Dietary data: (234293, 75)\n",
      "4. Socioeconomic data: (654425, 20)\n",
      "\n",
      "MERGING DATASETS\n",
      "==================================================\n",
      "Merged Data: (175899, 136)\n"
     ]
    }
   ],
   "source": [
    "# IMPORT LIBRARIES\n",
    "##################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from scipy.stats import skew\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "\n",
    "# DATA LOADING\n",
    "##############\n",
    "\n",
    "print(\"LOADING DATASETS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "anthro_data = pd.read_csv('anthro_data.csv')\n",
    "clinical_data = pd.read_csv('clinical_data.csv')\n",
    "dietary_data = pd.read_csv('dietary_data.csv')\n",
    "socio_data = pd.read_csv('socio_data.csv')\n",
    "\n",
    "print(f\"1. Anthropometric data: {anthro_data.shape}\")\n",
    "print(f\"2. Clinical data: {clinical_data.shape}\")\n",
    "print(f\"3. Dietary data: {dietary_data.shape}\")\n",
    "print(f\"4. Socioeconomic data: {socio_data.shape}\")\n",
    "\n",
    "# MERGING DATASETS\n",
    "##################\n",
    "\n",
    "print(\"\\nMERGING DATASETS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Merge on both hhnum and member_code\n",
    "merged_data = pd.merge(\n",
    "    clinical_data,\n",
    "    anthro_data,\n",
    "    on=['hhnum', 'member_code'],\n",
    "    how='inner',\n",
    "    suffixes=('_clinical', '_anthro')\n",
    ")\n",
    "\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    dietary_data,\n",
    "    on=['hhnum', 'member_code'],\n",
    "    how='inner',\n",
    "    suffixes=('', '_dietary')\n",
    ")\n",
    "\n",
    "merged_data = pd.merge(\n",
    "    merged_data,\n",
    "    socio_data,\n",
    "    on=['hhnum', 'member_code'],\n",
    "    how='inner',\n",
    "    suffixes=('', '_socio')\n",
    ")\n",
    "print(f\"Merged Data: {merged_data.shape}\")\n",
    "\n",
    "# ROW FILTERING\n",
    "###############\n",
    "\n",
    "# Dropping rows with no FBS values\n",
    "print(\"\\nDROPPING ROWS WITH NO FBS VALUES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check FBS column status\n",
    "print(\"Before Cleaning\")\n",
    "print(f\"   Total rows: {len(merged_data)}\")\n",
    "print(f\"   Missing FBS values: {merged_data['fbs'].isna().sum()}\")\n",
    "\n",
    "# Drop rows with missing FBS values\n",
    "merged_data = merged_data.dropna(subset=['fbs'])\n",
    "print(\"\\nAfter Cleaning\")\n",
    "print(f\"   Total rows: {len(merged_data)}\")\n",
    "print(f\"   Missing FBS values: {merged_data['fbs'].isna().sum()}\")\n",
    "\n",
    "# COLUMN FILTERING\n",
    "##################\n",
    "\n",
    "print(\"\\nREMOVING DUPLICATE COLUMNS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "admin_columns = ['hhnum', 'member_code']\n",
    "\n",
    "# Identify duplicate columns based on suffixes\n",
    "duplicate_cols = []\n",
    "for col in merged_data.columns:\n",
    "    for suffix in ['_clinical', '_anthro', '_dietary', '_socio']:\n",
    "        if col.endswith(suffix):\n",
    "            duplicate_cols.append(col)\n",
    "\n",
    "# Drop only the columns that actually exist\n",
    "all_cols_to_drop = admin_columns + duplicate_cols\n",
    "existing_cols_to_drop = [col for col in all_cols_to_drop if col in merged_data.columns]\n",
    "\n",
    "# Display columns to be removed (admin/duplicates) in a table\n",
    "admin_drop_df = pd.DataFrame({'': existing_cols_to_drop})\n",
    "print(f\"Administrative/Duplicate Columns to be removed ({len(existing_cols_to_drop)}):\")\n",
    "print(admin_drop_df)\n",
    "\n",
    "# Drop them\n",
    "merged_data = merged_data.drop(columns=existing_cols_to_drop, errors='ignore')\n",
    "\n",
    "# Analyze missing values before dropping\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': merged_data.columns,\n",
    "    'Missing_Count': merged_data.isnull().sum(),\n",
    "    'Missing_Percentage': (merged_data.isnull().sum() / len(merged_data)) * 100\n",
    "}).sort_values('Missing_Percentage', ascending=False)\n",
    "\n",
    "# Display columns with >50% missing\n",
    "high_missing = missing_summary[missing_summary['Missing_Percentage'] > 50]\n",
    "print(f\"\\nColumns with >50% missing values ({len(high_missing)}):\")\n",
    "print(high_missing[['Column', 'Missing_Percentage']])\n",
    "\n",
    "# Drop these columns\n",
    "columns_to_drop = high_missing['Column'].tolist()\n",
    "merged_data = merged_data.drop(columns=columns_to_drop)\n",
    "\n",
    "total_dropped = len(existing_cols_to_drop) + len(columns_to_drop)\n",
    "print(f\"\\nDropped {(total_dropped)} columns\")\n",
    "print(f\"Merged Data: {merged_data.shape}\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
